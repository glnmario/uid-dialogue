#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --nodes=1
#SBATCH --gres=gpu:1
#SBATCH --job-name=pb_ctx
#SBATCH --time=1:00:00
#SBATCH --output=slurm_output/%A.out
# https://servicedesk.surfsara.nl/wiki/display/WIKI/Lisa+usage+and+accounting
echo "${SLURM_JOB_ID}"
date

source ${HOME}/.bashrc
module purge
module load 2022
module load Anaconda3/2022.05
source "$(conda info --base)/etc/profile.d/conda.sh"
conda deactivate
conda activate stat-gen-eval-3.10

export ROOT="/home/${USER}/projects/uid-dialogue/"

bsz=4
n_sent=-1
ctx=dialogue_id
maxlen=1024
maxpos=56
dat=$(date +"%FT%T")

mkdir -p results/pb_gpt2-ft_${ctx}_${n_sent}_${maxlen}_${maxpos}_${dat}

#python3 -m torch.distributed.launch --nproc_per_node=1 --nnodes=1 --node_rank=0 
python3 src/contextualised_entropy.py \
	--data_path /lisa_migration/project/dmg_data/erp/data_clean/PB/analysis.csv \
	--out_path results/pb_gpt2-ft_${ctx}_${n_sent}_${maxlen}_${maxpos}_${dat} \
	--per_gpu_batch_size $bsz \
	--seed 0 \
	--n_sent ${n_sent} \
	--model_name gpt2 \
	--model_path /lisa_migration/project/dmg_data/erp/models/pb/gpt2_gpt2_bsz2_lr0.0001_epochs20_2021-06-02T03:30:42/ \
	--context_field ${ctx} \
	--max_seq_len ${maxlen} \
	--add_special_tokens \
	--max_position ${maxpos} \
	&> out/pb_gpt2-ft_${ctx}_${n_sent}_${maxlen}_${maxpos}_${dat}


